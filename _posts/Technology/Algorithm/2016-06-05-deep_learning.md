---

layout: post
title: 深度学习是个什么鬼
category: 技术
tags: Algorithm
keywords: 深度学习

---


## 前言

最近一阵听了一两个深度学习的讲座,有些不明觉厉,特总结一下

为什么要深度学习?从计算机编程的角度讲,解决问题的手段一般有两种

1. 将"规则"代码化
2. 穷举,利用"规则"干掉不符合条件的

问题是,对于有些东西,无法用规则来描述,或者即便能够描述,对计算能力的要求也过高.这迫使人们使用新的方法来解决问题,即学习人脑的思维方式.

三百多页ppt，就说比较好的学习材料[李宏毅 / 一天搞懂深度學習](https://www.slideshare.net/tw_dsconf/ss-62245351?qid=108adce3-2c3d-4758-a830-95d0a57e46bc)

[Deep Learning](http://www.deeplearningbook.org/)

## 人脑神经网络

[神经元之间的连接网络](http://www.xlzx.com/cgi/xr_html/articles/NLP/2796.html)

一个人在出生之前，脑中的1000亿个神经元已经几乎全部准备好，而神经元之间的连接网络则是十分稀疏的。因为婴儿未能意识思考，故此，他只会凭外界的刺激而制造连接网络。

任何声音、景物、身体活动，只要是新的(第一次)，都会使得脑里某些神经元的树突和轴突生长，与其他神经元连接，构成新的网络。同样的刺激第二次出现时，会使第一次建立的网络再次活跃。就是说，新网络只能在有新刺激的情况下产生。一个人的一生之中，不断有新的网络产生出来，同时有旧的网络萎缩、消失。

一个旧的网络，对同样的刺激会特别敏感，每次都会比前一次启动得更快、更有力。多次之后，这个网络便会深刻到成为习惯或本能了。这便是学习和记忆的成因。



## 人工智能 ==> 机器学习 ==> 深度学习

[「人工智能入门」AI 是什么？](https://zhuanlan.zhihu.com/p/24919118)

大多数机器学习的目标是为特定场景开发**预测引擎**，一个算法将接收到一个域的信息（例如，一个人过去观看过的电影），权衡输入做出一个有用的预测（未来想看的不同电影的概率）

常用的有超过15种机器学习方法，每种方法使用不同的算法结构以基于接收的数据优化预测。

## 《神经网络与深度学习》小结

主线：

1. 神经元如何模拟
2. 神经元之间如何连接
3. 简单神经网络
4. 多层神经网络，分层是人脑学习的基本规律



模拟一个神经元：

1. 信号源处理：`s=p1w1+p2w2+p3w3+pnwn+b`
2. 传递函数：f(s)

各个变量的含义

1. p代表树突，一个输入信号源
2. w代表树突的强度权重
3. f(s)，比如s是一个任意整数值，而要求的输出只能是0或1两个值，这就需要f(s)做一个转换。

神经元之间的连接不是固定不变的，在人的学习和成长过程中，一些新的连接会被逐渐建立起来，还有一些连接可能会消失。外界刺激就是神经网络的输入，在接收刺激后，刺激信号将传递到整个网络中，影响所有的神经元状态，神经元之间彼此连接并相互制约影响，不断调整彼此间的连接强度，直到达到稳定的状态，并最终对刺激做出反应。神经元之间的关系变迁形成了生物体的学习过程。

训练过程：

1. 在上述神经元的表达式中w和b随机确定，p、s根据训练数据确定，f(s)有固定的几种选型，貌似根据经验确定
2. 根据实际输出与s的误差，校正w、b

据总结，可以得出本书线索

1. 单层神经网络：确定输入特征，单层，根据一定的数据训练即可
2. 多层神经网络（浅层学习）：确定输入特征，一层中间层，输出层，确定每层神经元数量（大于输入特征数，具体值依赖对精度和运行速度的权衡），根据一定的数据训练即可。训练算法：BP算法。BP算法可以训练五层（三个中间层）以内的神经网络。
3. 深度神经网络（深度学习）：输入特征，多层（五层以上）中间层（分层或分级处理是大脑识别一个物体的主要过程），输出层。涉及到特征选取（基于经验无法确定的话，便要学习特征）、中间层数确定（根据经验）、单层训练、回归训练等问题。

	深度学习首先利用无监督学习对每一层进行逐层**预训练**去**学习**特征；每次单独训练一层，并将训练结果作为更高一层的输入；然后到最上层改用监督学习从上到下进行微调去学习**模型**。

	 
任何事物都可以划分成粒度合适的浅层特征（或者通过了解，或者通过特征学习），这些浅层特征可以作为第二层输入特征。


## 自动编码器

如何学习特征，用到了自编码器。参考文章

1. [Deep Learning模型之：AutoEncoder自编码器](http://blog.csdn.net/u010555688/article/details/24438311)
2. [系统学习深度学习（二） --自编码器，DA算法，SDA，稀疏自编码器
](http://www.voidcn.com/blog/app_12062011/article/p-6370385.html)

自动编码器基于这样一个事实：原始input（设为x）经过加权（W、b)、映射/传递函数（Sigmoid）之后得到y，再对y反向加权映射回来成为z。

通过反复迭代训练（W、b），使得误差函数最小，即尽可能保证z近似于x，即完美重构了x。

那么可以说（W、b）是成功的，很好的学习了input中的关键特征，不然也不会重构得如此完美。Vincent在2010年的论文中做了研究，发现只要训练W就可以了。

[深度学习系列（四）：什么是稀疏编码](http://blog.csdn.net/on2way/article/details/50389968)

## 小结

本段可能有错误，会随着学习的深入逐步调整。

笔者是java开发，暂时无意对深度学习进行深入学习，但通过对相关材料的手机，基本确定了深度学习为什么可用？

1. 模拟人工神经网络，用数学的方式模拟了神经元。
2. 神经网络的组成机制：多个中间层、加上输入输出，构成神经网络。上一层输出是下一层的输入，不可跨层连接。正好对上了“分层是人脑学习的基本规律”
3. 训练，定义神经元的输入输出，初始随机设置(W，b）随后不断迭代，根据误差调整(W，b）
4. 逐层训练，不同场景下（训练数据是否带标签（一般是分类结果）），训练方法不同（用作反馈作用的误差的定义方式不同）
