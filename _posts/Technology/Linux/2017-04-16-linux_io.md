---

layout: post
title: java io涉及到的一些linux知识
category: 技术
tags: Linux
keywords: network 

---

## 简介

## io设备

磁盘(和内存)是一个可寻址的大数组（内存寻址：段 ==> 页 => 字节，磁盘寻址 磁盘 ==> xx ==> 字节），而os和应用都无法直接访问这个大数组（**强调一下，即便是os，也是通过文件系统，即`/xx/xx`的方式来访问文件的。这也是为什么load os的时候，有一个初始化文件系统的过程**）。文件系统则是更高层抽象，文件系统定义了文件名、路径、文件、文件属性等抽象，文件系统决定这些抽象数据保存在哪些块中。

||设备|
|---|---|
|面向流|tty、socket|
|面向块|磁盘|

当我们需要进行文件操作的时候，5个API函数是必不可少的：Create，Open，Close，Write和Read函数实现了对文件的所有操作。PS：很多时候，觉得close方法没用，但一个文件io都会占用一个fd句柄，close便用于释放它们。

## 中断和挂起

中断和挂起不是一回事儿，中断不一定引起当前进程的挂起。**中断只是当前cpu停止执行进程代码。**这里有两个重点：

1. 当前cpu，这意味着进程可以立刻被其它cpu执行
2. 进程代码，当前cpu转而执行中断处理程序

挂起则是，进程等待一定的条件，在条件满足之前，不会被调度到任何cpu执行。

||触发者|反应|其它|
|---|---|---|---|
|硬中断|硬件|当前cpu保存当前进程现场，执行中断处理程序|时钟中断会引起当前进程的挂起，其它中断则不一定|
|软中端|当前使用cpu的进程|cpu将当前运行的现场状态保存在堆栈中，为的不是切换进程，而是执行完系统调用处理程序后，接着执行该进程|某些系统调用处理程序会挂起当前进程|

## 硬中断和软中断

删改自[进程内核栈、用户栈](http://www.cnblogs.com/shengge/articles/2158748.html)

内核在创建进程的时候，在创建task_struct的同时，会为进程创建相应的堆栈。每个进程会有两个栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，cpu堆栈指针寄存器里面的内容是用户堆栈地址，使用用户栈；当进程在内核空间时，cpu堆栈指针寄存器里面的内容是内核栈空间地址，使用内核栈。

当进程因为中断或者系统调用而陷入内核态之行时，进程所使用的堆栈也要从用户栈转到内核栈。

如何相互切换呢？

进程陷入内核态后，先把用户态堆栈的地址保存在内核栈之中，然后设置堆栈指针寄存器的内容为内核栈的地址，这样就完成了用户栈向内核栈的转换；当进程从内核态恢复到用户态执行时，在内核态执行的最后，将保存在内核栈里面的用户栈的地址恢复到堆栈指针寄存器即可。这样就实现了内核栈和用户栈的互转。

那么，我们知道从内核转到用户态时用户栈的地址是在陷入内核的时候保存在内核栈里面的，但是在陷入内核的时候，我们是如何知道内核栈的地址的呢？

关键在进程从用户态转到内核态的时候，进程的内核栈总是空的。这是因为，一旦进程从内核态返回到用户态后，内核栈中保存的信息无效，会全部恢复。因此，每次进程从用户态陷入内核的时候得到的内核栈都是空的，直接把内核栈的栈顶地址给堆栈指针寄存器就可以了。

一个进程的运行过程：

|状态|用户态|内核态|用户态|
|---|---|---|---|
|代码|用户手写的程序代码，触发了系统调用|相关系统调用处理程序|用户手写的程序代码返回，继续执行|


联系下上文的read、write、select、 fcntl(fd, F_SETFL, flags | O_NONBLOCK)等系统调用，或许对java nio有一些会心的体会。

## 缓冲区


缓冲区的表现形式：

1. 对于网络：socket有一个send buffer和receive buffer；
2. 对于磁盘：内存会有一个专门的区域划分为缓冲区，由操作系统管理

[浅谈TCP/IP网络编程中socket的行为](http://www.cnblogs.com/promise6522/archive/2012/03/03/2377935.html)，无论是磁盘io还是网络io，应用程序乃至r/w系统调用都不负责数据实际的读写（接收/发送）。对于每个socket，拥有自己的send buffer和receive buffer。以write操作为例，write成功返回，只是buf中的数据被复制到了kernel中的TCP发送缓冲区。至于数据什么时候被发往网络，什么时候被对方主机接收，什么时候被对方进程读取，系统调用层面不会给予任何保证和通知。已经发送到网络的数据依然需要暂存在send buffer中，只有收到对方的ack后，kernel才从buffer中清除这一部分数据，为后续发送数据腾出空间。**这些控制皆发生在TCP/IP栈中，对应用程序是透明的**，应用程序继续发送数据，最终导致send buffer填满，write调用阻塞。

这就跟我潜意识的认知，稍稍有点不同。我以前的认为是，一个write操作，数据从发起，到调用网卡驱动发数据，都是一起干完的。

缓冲区既可以处理各部件速度不一致的矛盾，也可以作为各个子系统的边界存在。


## 同步异步

[多种I/O模型及其对socket效率的改进](http://mickhan.blog.51cto.com/2517040/1586370)


对于一次IO访问（以read举例），数据会先被拷贝到**操作系统内核的缓冲区**中，然后才会从操作系统内核的缓冲区拷贝到**应用程序的地址空间**。所以说，当一个read操作发生时，它会经历两个阶段：

1. 等待数据准备 (Waiting for the data to be ready)
2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。参见[Linux IO模式及 select、poll、epoll详解](https://segmentfault.com/a/1190000003063859)

文中关于异步io的描述：用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

也就是说，不管是阻塞、非阻塞、多路复用io，其本质都是用户进程主动去发现socket send/receive buffer是否ready，而异步io则是内核主动向用户进程发起通知的。
从这个角度看，异步有点双工通信的意味，而同步只是单工的。

在多线程模型下，多路复用io和异步io从感官上不太明显，因为多路复用io在5个API函数Create，Open，Close，Write和Read之外，提供了select函数，**注意，不是五大api函数了**，**r/w设置为非阻塞，阻塞转移到了select上**。netty甚至完全可以将多路复用io封装为异步的。但在单线程模型下，两者还是有本质差异的。
        

## 阻塞非阻塞

我们从代码上理解下阻塞和非阻塞的含义

	ssize_t read(int fd, void *buf, size_t count);
	ssize_t write(int fd, const void *buf, size_t count);

为socket设置nonblocking

	// 设置一个文件描述符为nonblock
	int set_nonblocking(int fd){
	    int flags;
	    if ((flags = fcntl(fd, F_GETFL, 0)) == -1)
	        flags = 0;
	    return fcntl(fd, F_SETFL, flags | O_NONBLOCK);
	}

[浅谈TCP/IP网络编程中socket的行为](http://www.cnblogs.com/promise6522/archive/2012/03/03/2377935.html)讲到了两个关键问题

1. read/write的语义：为什么会阻塞？
2. blocking（默认）和nonblocking模式下read/write行为的区别。
      
或者，我们可以说，**blocking和nonblocking的本质，就是影响了read/write（可能还有connect）的语义**

1. blocking，表示等，缓冲区有数据（read）或有足够的空间
2. nonblocking，成就成，不成就返回-1


## select

java nio中，介绍channel用的是：A nexus（连结、连系） for I/O operations.那么selector便是 a nexus for `int select(int nfds, fd_set *readfds, fd_set *writefds,fd_set *exceptfds, struct timeval *timeout);`

据此，我们可以认识到，我们感觉的**java nio是一系列机制的综合体现**：

1. io操作分为两个部分：

	1. 是否可以进行io操作（socket的send buffer和receive buffer是否可用）；
	2. 实际进行io操作（不同地址空间复制buffer）
2. fd option 设置为 O_NONBLOCK，如果不可r/w，r/w系统调用处理程序立即返回，进程从内核态返回用户态。一个完整的io数据的读取就成了

		while(xx){
			read/write
		}
	
	这效果跟不设置O_NONBLOCK也差不多。

	
3. 因此将**多个网络io**第一部分的判断集中交给select系统调用。

也就是说，原先一个系统调用可以完成的事情，现在交给了两个系统调用，触发这两个系统调用的可能不是一个线程。

|io编程中线程理想状态|问题|io模型|线程|适用|
|---|---|---|---|---|
|有数据则处理，无数据则干别的|上层应用和网卡本质上是一个消费-生产关系，等待是免不了的|非阻塞，io复用或异步|socket与线程是多对一关系|io数据频繁，但单次数据较少|
|有数据则处理，无数据则阻塞|一个socket占用一个线程，线程数过多也是一个问题|||单次io数据量较大|


## 引用

[存储之道 - 51CTO技术博客 中的《一个IO的传奇一生》](http://alanwu.blog.51cto.com/3652632/d-8)



